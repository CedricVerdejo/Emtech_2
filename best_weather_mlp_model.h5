import pandas as pd
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Activation
from keras.callbacks import ModelCheckpoint, LearningRateScheduler
from keras.models import model_from_json
from sklearn.metrics import mean_squared_error
import os
from google.colab import drive
drive.mount('/content/drive')

dataset_path = "/content/drive/MyDrive/Emtech 2/Multi-class Weather Dataset"

image_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    directory=dataset_path,
    image_size=(128, 128),
    batch_size=32,
    labels='inferred',
    label_mode='categorical'
)
weather_classes = image_dataset.class_names
print(weather_classes)
# Separate images and labels from the dataset and store them in lists
image_data = []
label_data = []

for batch_images, batch_labels in image_dataset:
    for idx in range(batch_images.shape[0]):
        image_data.append(batch_images[idx].numpy())
        label_data.append(batch_labels[idx].numpy())

# Convert lists to NumPy arrays
x_train = np.array(image_data)
y_train = np.array(label_data)

# Duplicate training data to use as testing data
x_test = x_train
y_test = y_train

# Ensure the image data is in float32 format
x_train = x_train.astype('float32')
x_train = x_train.astype(np.float32)
x_test = x_test.astype(np.float32)

# Normalize pixel values to the range [0, 1]
max_pixel_value = 255.0
x_train = x_train / max_pixel_value
x_test = x_test / max_pixel_value
# Display the shapes of the input and output datasets
print("Training features shape:", x_train.shape)
print("Testing features shape:", x_test.shape)
print("Training labels shape:", y_train.shape)
print("Testing labels shape:", y_test.shape)
# Display the first 100 training images in a 10x10 grid
fig, axes = plt.subplots(nrows=10, ncols=10, figsize=(10, 10))
index = 0

for row in range(10):
    for col in range(10):
        axes[row][col].imshow(x_train[index].reshape(128, 128, 3), aspect='auto')
        axes[row][col].axis('off')  
        index += 1

plt.tight_layout()
plt.show()
# Define a function to build and compile the neural network model
def build_model():
    model = Sequential([
        Flatten(input_shape=(128, 128, 3)),
        Dense(128, activation='relu'),
        Dense(64, activation='relu'),
        Dense(4, activation='softmax')
    ])
    
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# Instantiate the model
model = build_model()

# Split the dataset into training and validation sets
x_train, x_val, y_train, y_val = train_test_split(
    x_train, y_train, test_size=0.2, random_state=42
)

# Train the model and store the training history
history = model.fit(
    x_train,
    y_train,
    epochs=150,
    batch_size=2000,
    validation_split=0.2
)
history.history.keys()
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
results = model.evaluate(x_test, y_test, verbose = 1)
print('test loss, test acc:', results)
model.save('/content/drive/MyDrive/Emtech 2/best_weather_mlp_model.h5')
checkpoint = ModelCheckpoint("/content/drive/MyDrive/Emtech 2/best_weather_mlp_model.h5",
                             monitor='val_accuracy',
                             verbose=1,
                             save_best_only=True,
                             mode='max')


model.fit(x_train, y_train,
          validation_split=0.2,
          epochs=20,
          callbacks=[checkpoint], verbose=1);
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing import image
import numpy as np
from google.colab import drive
import os
import matplotlib.pyplot as plt
from PIL import Image

# Mount Google Drive
if not os.path.exists('/content/drive'):
    drive.mount('/content/drive')
else:
    print("Google Drive is already mounted.")

# Load the trained model
model_path = '/content/drive/MyDrive/Emtech 2/best_weather_mlp_model.h5'
model = keras.models.load_model(model_path)

# Define class labels (must match training order)
class_names = ['cloudy', 'rain', 'shine', 'sunrise']

# Image preprocessing function
def preprocess_image(image_path):
    img_for_model = image.load_img(image_path, target_size=(128, 128))
    img_array = image.img_to_array(img_for_model)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0

    # Load original image for display 
    original_img = Image.open(image_path)
    return img_array, original_img

# Image file paths
image_paths = [
    '/content/drive/MyDrive/Emtech 2/pic 1', 
    '/content/drive/MyDrive/Emtech 2/pic2.jpg'
]

# Create plot
plt.figure(figsize=(10, 5))

# Loop through images and show predictions
for i, img_path in enumerate(image_paths):
    processed_img, display_img = preprocess_image(img_path)
    prediction = model.predict(processed_img)
    predicted_index = np.argmax(prediction)
    predicted_label = class_names[predicted_index]

    # Plot image with label
    plt.subplot(1, len(image_paths), i + 1)
    plt.imshow(display_img)
    plt.title(f"Predicted: {predicted_label}")
    plt.axis('off')

plt.tight_layout()
plt.show()
from tensorflow.keras.models import load_model

best_model = load_model('/content/drive/MyDrive/Emtech 2/best_weather_mlp_model.h5')

class_names = ['Cloudy', 'Rain', 'Shine', 'Sunrise']

data = "/content/drive/MyDrive/Emtech 2/Multi-class Weather Dataset"

image_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    data,
    image_size=(64, 64),
    batch_size=32,
    labels='inferred',
    label_mode='categorical'
)
from tensorflow.keras.models import load_model
from sklearn.metrics import confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

best_model = load_model('/content/drive/MyDrive/Emtech 2/best_weather_mlp_model.h5')

class_names = ['Cloudy', 'Rain', 'Shine', 'Sunrise']

data = "/content/drive/MyDrive/Emtech 2/Multi-class Weather Dataset"

image_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    data,
    image_size=(128, 128),
    batch_size=32,
    labels='inferred',
    label_mode='categorical'
)

# Define the function to evaluate the model effectiveness
def evaluate_model_effectiveness(model, x_train, y_train, x_test, y_test, class_names):
    """
    Evaluates the effectiveness of a given model.

    Args:
        model: The trained Keras model.
        x_train: Training feature data.
        y_train: Training target data (one-hot encoded).
        x_test: Testing feature data.
        y_test: Testing target data (one-hot encoded).
        class_names: A list of class names.
    """
    # Evaluate the model on the test set
    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)
    print(f"Test Loss: {loss:.4f}")
    print(f"Test Accuracy: {accuracy:.4f}")

    # Get predictions for the test set
    y_pred = model.predict(x_test)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true_classes = np.argmax(y_test, axis=1)

    # Generate Confusion Matrix
    cm = confusion_matrix(y_true_classes, y_pred_classes)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix')
    plt.show()

    # Generate Classification Report
    print("\nClassification Report:")
    print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))


images = []
labels = []
for images_batch, labels_batch in image_dataset:
    for i in range(images_batch.shape[0]):
        images.append(images_batch[i].numpy())
        labels.append(labels_batch[i].numpy())

x_train = np.array(images)
y_train = np.array(labels)

x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)

# Ensure the data is scaled correctly before evaluating
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255.0
x_test /= 255.0


# Call the function after it has been defined
evaluate_model_effectiveness(best_model, x_train, y_train, x_test, y_test, class_names)
